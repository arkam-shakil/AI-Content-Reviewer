import google.generativeai as genai

# Configure the API key
genai.configure(api_key="AIzaSyC4JNxnxdAtQ9k51qtfM8MvWkKImuQrx7Y")

# Set up the model generation configuration
generation_config = {
	"temperature": 1,
	"top_p": 0.95,
	"top_k": 0,
	"max_output_tokens": 2048,
}

# Define safety settings to filter harmful content
safety_settings = [
	{
		"category": "HARM_CATEGORY_HARASSMENT",
		"threshold": "BLOCK_MEDIUM_AND_ABOVE"
	},
	{
		"category": "HARM_CATEGORY_HATE_SPEECH",
		"threshold": "BLOCK_MEDIUM_AND_ABOVE"
	},
	{
		"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
		"threshold": "BLOCK_MEDIUM_AND_ABOVE"
	},
	{
		"category": "HARM_CATEGORY_DANGEROUS_CONTENT",
		"threshold": "BLOCK_MEDIUM_AND_ABOVE"
	},
]

# Initialize the generative model
model = genai.GenerativeModel(
	model_name="gemini-1.5-pro-latest",
	generation_config=generation_config,
	safety_settings=safety_settings
)

try:
	# Start the conversation
	convo = model.start_chat(history=[])
	
	# Take instructions from the user
	instructions = input("Enter the instructions: ")

	# Take the file path as input
	file_path = input("Enter the path to the file: ")

	# Check if the file exists
	if os.path.exists(file_path):
		# Read the content of the file in binary mode
		with open(file_path, "rb") as file:
			file_content = file.read().decode("utf-8", errors="ignore")  # Decode as UTF-8 with error handling
		
		# Concatenate the instructions with the file content
		prompt = instructions + "\n\n" + file_content
		
		# Send the prompt to the model
		convo.send_message(prompt)

		# Check if the last response is empty
		if convo.last is None or convo.last.text == "":
			print("The response was blocked for safety reasons.")
		else:
			# Print the response generated by the model
			print(convo.last.text)
	else:
		print("File not found.")

except Exception as e:
	# Handle any exceptions that occur during execution
	print("An error occurred:", str(e))
